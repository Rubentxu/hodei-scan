# **√âPICA Maestra: An√°lisis de Flujo de Datos y Dise√±o Arquitect√≥nico (Nivel 3)**

**Visi√≥n Actualizada:** No solo detectaremos vulnerabilidades de seguridad, sino que tambi√©n analizaremos la **estructura profunda y la salud arquitect√≥nica** del software, proporcionando a los desarrolladores y arquitectos una inteligencia sin precedentes sobre el acoplamiento y el dise√±o de su c√≥digo.

Esta √©pica detalla la creaci√≥n de **`hodei-deep-analysis-engine`**, la librer√≠a central en Rust que servir√° como el "cerebro" para todos nuestros Extractores Profundos (Nivel 3). Su misi√≥n es abstraer la ciencia computacional compleja del an√°lisis de programas, permitiendo que los extractores de cada lenguaje se enfoquen en la sem√°ntica de su ecosistema en lugar de reinventar algoritmos de grafos.

Esta librer√≠a no solo proporcionar√° un motor de **Taint Analysis** de clase mundial, sino que, de forma innovadora, integrar√° el **An√°lisis de Dise√±o Arquitect√≥nico** basado en el concepto de Connascence. Es la "Academia" donde entrenamos a nuestros "Agentes de √âlite" para ser tanto detectives de seguridad como arquitectos de software.

### üìä Estado Actual (Noviembre 2025)

**INVESTIGACI√ìN COMPLETADA:** Se ha realizado una evaluaci√≥n exhaustiva de las tecnolog√≠as y del estado actual del c√≥digo. Los resultados muestran que **el proyecto ya tiene una base s√≥lida implementada**.

**Ver documentos de referencia:**
- `/docs/INVENTARIO-NIVEL3-ACTUAL.md` - An√°lisis detallado del c√≥digo existente
- `/docs/ANALYSIS-CONNASCENCE-EPIC20.md` - Investigaci√≥n de tecnolog√≠as y propuesta arquitect√≥nica

### Objetivo de Negocio
Desarrollar un activo tecnol√≥gico reutilizable que **reduzca dr√°sticamente el coste y el tiempo** para construir analizadores profundos para nuevos lenguajes. Esto nos permitir√° escalar nuestra oferta de an√°lisis de alta gama y proporcionar una inteligencia sobre el c√≥digo (tanto de seguridad como de dise√±o) que es inalcanzable para nuestros competidores.

### M√©tricas de √âxito
-   **Reutilizaci√≥n**: >80% del c√≥digo de an√°lisis de flujo y acoplamiento debe residir en esta librer√≠a, no en los extractores espec√≠ficos del lenguaje.
-   **Rendimiento**: El motor de Taint Analysis debe ser capaz de procesar un grafo de 100,000 nodos en < 5 segundos.
-   **Flexibilidad**: A√±adir una nueva clase de vulnerabilidad de Taint (ej. "Inyecci√≥n LDAP") debe ser posible modificando solo un fichero de configuraci√≥n TOML, sin recompilar el motor.
-   **Expresividad**: El motor debe ser capaz de detectar al menos 4 tipos de Connascence est√°tica (Posici√≥n, Significado, Tipo, Nombre).

### üõ†Ô∏è Tecnolog√≠as Evaluadas (2025)

| Tecnolog√≠a | Versi√≥n | Estado | Evaluaci√≥n |
|------------|---------|--------|------------|
| **datafrog** | v2.0.1 | ‚úÖ √ìptimo | Motor Datalog mantenido por rust-lang, >5,800 dependientes |
| **petgraph** | v0.6.5 | ‚úÖ Excelente | Soporta 100k+ nodos, algoritmos completos (astar, dijkstra) |
| **tree-sitter** | v0.25.10 | ‚úÖ Madura | 22,600+ stars, grammars para JS/TS/Java/Python/Rust |

**Conclusi√≥n:** Las tecnolog√≠as est√°n en su mejor momento y perfectamente adaptadas al caso de uso.


---

## 2. Contexto T√©cnico

### 2.1. Problema Actual
Construir un analizador de flujo de datos desde cero para cada lenguaje es un proyecto de a√±os. Los algoritmos para construir grafos de flujo, propagar informaci√≥n y analizar acoplamiento son complejos y propensos a errores. Sin una fundaci√≥n com√∫n, cada equipo de extractores duplicar√≠a esfuerzos, introducir√≠a inconsistencias y se mover√≠a a una velocidad glacial.

### 2.2. Soluci√≥n: Una Librer√≠a de Primitivas de An√°lisis

Crearemos una librer√≠a en Rust agn√≥stica al lenguaje que proporcionar√° las "herramientas del detective" ya listas para usar. El trabajo de un nuevo extractor de Nivel 3 se convierte en un "trabajo de integraci√≥n": tomar la representaci√≥n espec√≠fica de un lenguaje (de `tree-sitter` o similar) y "traducirla" a las estructuras de datos gen√©ricas de esta librer√≠a.

```mermaid
graph TD
    subgraph "Extractor Profundo de Java<br>Cliente de la Librer√≠a"
        A[Parser de Java] --> B{Traductor Espec√≠fico de Java};
        B --> C[Llamadas a hodei-deep-analysis-engine];
    end

    subgraph "hodei-deep-analysis-engine (Librer√≠a Central)"
        D[Definici√≥n del SemanticModel]
        E[Motor de Taint Analysis con datafrog]
        F[Motor de An√°lisis de Connascence]
    end

    subgraph "Salida del Extractor"
        G((IR Parcial con Hechos Profundos<br/><i>TaintSource, Coupling...</i>))
    end
    
    C -- Usa --> D & E & F;
    C -- Genera --> G;

    style D fill:#cde,stroke:#333,stroke-width:2px
    style E fill:#cde,stroke:#333,stroke-width:2px
    style F fill:#cde,stroke:#333,stroke-width:2px
```

---

## 2.5. **Estado Real de Implementaci√≥n** (Actualizado 2025-11-13)

### üìã Inventario de Componentes Existentes

**PROGRESO ACTUAL:** 40-50% ya implementado

#### ‚úÖ **Lo que YA EXISTE (Reutilizable)**

1. **hodei-pattern-engine** (100% completo)
   - Ubicaci√≥n: `crates/hodei-pattern-engine/`
   - **Funcional:** Tree-sitter integration con cache LRU, YAML rules, multi-lenguaje
   - **Reutilizar:** ‚úÖ Listo para usar como base de parsing

2. **FlowIndex con petgraph** (90% completo)
   - Ubicaci√≥n: `crates/hodei-engine/src/store/flow_index.rs`
   - **Funcional:** DiGraph con algoritmos astar, dijkstra, reachable queries
   - **Reutilizar:** ‚úÖ Base perfecta para Taint Analysis (solo falta datafrog overlay)

3. **IR Schema Cap'n Proto** (100% completo)
   - Ubicaci√≥n: `crates/hodei-ir/schema/facts.capnp`
   - **Funcional:** TaintSource, TaintSink, Sanitization ya definidos
   - **Reutilizar:** ‚úÖ Schema perfecto, listo para usar

4. **hodei-declarative-extractors** (30% completo)
   - Ubicaci√≥n: `crates/hodei-declarative-extractors/`
   - **Estado:** Estructura lista, pero usa AST stub (no tree-sitter real)
   - **Reutilizar:** ‚ö†Ô∏è Solo estructura, necesita conexi√≥n tree-sitter real

#### ‚ùå **Lo que FALTA (Por implementar)**

1. **hodei-deep-analysis-engine** - Crate principal **NO EXISTE**
2. **TaintPropagator con datafrog** - 0% implementado
3. **ConnascenceAnalyzer** - 0% implementado
4. **SemanticModel Builder** - 0% implementado
5. **Policy TOML parser** - 0% implementado
6. **CFG/DFG desde AST** - 0% implementado

### üéØ **Plan de Implementaci√≥n Optimizado**

**ESTRATEGIA:** Aprovechar lo existente (5-6 semanas vs 12-16 semanas)

#### **Paso 1: Crear hodei-deep-analysis-engine (Semana 1)**
```bash
cargo new --lib crates/hodei-deep-analysis-engine
[dependencies]
datafrog = "2.0.1"                    # NUEVO
petgraph = { workspace = true }        # REUTILIZAR
hodei-ir = { path = "../hodei-ir" }    # REUTILIZAR
```

#### **Paso 2: Integrar datafrog sobre FlowIndex (Semana 1-2)**
```rust
// Overlay de datafrog en FlowIndex existente
pub struct TaintPropagator {
    flow_index: FlowIndex,  // Ya existe
    iteration: Iteration,   // NUEVO con datafrog
    sources: Variable<(FlowId, VariableName)>,
    sinks: Variable<(FlowId, SinkCategory)>,
    // ...
}
```

#### **Paso 3: Conectar tree-sitter real (Semana 2-3)**
```rust
// Reemplazar AST stub con tree-sitter real
impl MultiLanguageParser {
    pub fn parse_real(&self, lang: Language, code: &str) -> Result<ParseResult> {
        let parser = Parser::new().set_language(language)?;
        let tree = parser.parse(code, None)?;
        Ok(self.tree_to_ast(tree.root_node()))
    }
}
```

#### **Paso 4: ConnascenceAnalyzer con TDD (Semana 3-4)**
```rust
impl ConnascenceAnalyzer {
    pub fn detect_positional(&self) -> Vec<CouplingFinding> {
        // Heur√≠stica: 3+ par√°metros mismo tipo = CoP
    }
}
```

#### **Paso 5: SemanticModel Builder (Semana 4-5)**
```rust
impl SemanticModel {
    pub fn from_ast(ast: &ASTNode) -> Result<Self> {
        let cfg = self.build_cfg(ast)?;
        let dfg = self.build_dfg(&cfg)?;
        Ok(SemanticModel { cfg, dfg, ... })
    }
}
```

#### **Paso 6: Policy TOML + Integraci√≥n (Semana 5-6)**
```toml
# pol√≠tica.toml
[[sources]]
pattern = "request.*"
source_type = "HttpRequest"
tags = ["PII", "UserInput"]

[[sinks]]
pattern = "executeQuery"
category = "SqlQuery"
severity = "critical"
```

### üí° **Ventajas de la Estrategia**

1. **M√°xima reutilizaci√≥n:** 40-50% del trabajo ya hecho
2. **Riesgo m√≠nimo:** Componentes probados en producci√≥n
3. **Time-to-market:** 5-6 semanas en lugar de 12-16
4. **Calidad:** Tests y documentaci√≥n ya existentes

### üìä **M√©tricas Revisadas**

| M√©trica | Objetivo Original | Estimaci√≥n Revisada |
|---------|-------------------|---------------------|
| **Tiempo desarrollo** | 12-16 semanas | **5-6 semanas** |
| **C√≥digo reutilizable** | 80% | **40-50% ya implementado** |
| **Nuevos tests** | 100% | **60% reutilizables** |
| **Riesgo t√©cnico** | Alto | **Bajo** (tecnolog√≠as maduras) |

**CONCLUSI√ìN:** El proyecto est√° **mucho m√°s avanzado** de lo esperado. La base existente permite un desarrollo mucho m√°s r√°pido y seguro.

---

### **√âPICA-20 (v2.0): La Fundaci√≥n del An√°lisis Profundo y Arquitect√≥nico (`hodei-deep-analysis-engine`)**

**Objetivo (Actualizado):** Crear la librer√≠a central que contenga la l√≥gica para el an√°lisis de flujo de datos **Y** para el an√°lisis de acoplamiento estructural, basado en el concepto de Connascence. Es la "Academia de Esp√≠as y Arquitectos".

*   **HU-20.01: Dise√±ar un `SemanticModel` Rico en Contexto.** ‚ö†Ô∏è **REVISADO**
    > **Como** desarrollador del motor, **quiero** que las estructuras de datos del `SemanticModel` incluyan no solo grafos de flujo, sino tambi√©n una representaci√≥n expl√≠cita de **√°mbitos (scopes), jerarqu√≠as de tipos y un grafo de acoplamiento**, **para que** podamos realizar an√°lisis que entiendan el contexto completo del c√≥digo.
    **Estado Real:** Base existente en `hodei-declarative-extractors` (ASTNode), necesita conexi√≥n con tree-sitter real y petgraph.
    **Criterios de Aceptaci√≥n:**
      *   ‚úÖ `struct ASTNode` ya definida (en hodei-declarative-extractors)
      *   ‚ö†Ô∏è `struct SemanticModel` por crear (basado en ASTNode)
      *   ‚ö†Ô∏è `struct ControlFlowGraph` por crear (usando petgraph::Graph)
      *   ‚ö†Ô∏è `struct DataFlowGraph` por crear (usando petgraph::Csr)
      *   ‚ö†Ô∏è `struct ScopeTree` por crear (nuevo)
      *   ‚ö†Ô∏è `struct CouplingGraph` por crear (petgraph::Graph con ConnascenceEdge)
      *   [ ] Todas las estructuras son agn√≥sticas a cualquier lenguaje de programaci√≥n espec√≠fico.
    **Reutilizaci√≥n:** hodei-declarative-extractors provee base, petgraph ya disponible en workspace.

*   **HU-20.02: Implementar el Motor de Taint Analysis.** ‚úÖ **REVISADO**

    **Como** desarrollador del motor, **quiero** integrar `datafrog` para crear un `TaintPropagator` gen√©rico, declarativo y ultra-performante, **para que** podamos modelar problemas complejos de flujo de datos como un conjunto de reglas l√≥gicas, separando la "f√≠sica" de la propagaci√≥n de la sem√°ntica espec√≠fica del lenguaje.

    **Estado Real:** FlowIndex con petgraph ya implementado (crates/hodei-engine/src/store/flow_index.rs), solo necesita overlay de datafrog.
    
*   **Criterios de Aceptaci√≥n:**
    *   ‚ö†Ô∏è Nueva dependencia `datafrog = "2.0.1"` por a√±adir
    *   ‚ö†Ô∏è Reglas Datalog por definir (ej. `Tainted(Y) :- FlowsTo(Y, X), Tainted(X).`)
    *   ‚úÖ `FlowIndex` con `DiGraph`, `astar`, `dijkstra` ya implementado
    *   ‚ö†Ô∏è Funci√≥n `run_taint_analysis` por crear (combinando FlowIndex + datafrog)
    *   ‚ö†Ô∏è Soporte `Sanitizers` por implementar
    *   [ ] Sanitizers act√∫an como "retract" en Datalog, deteniendo propagaci√≥n
    **Reutilizaci√≥n:** FlowIndex provee 70% del trabajo (grafo, algoritmos, queries)

*   **HU-20.03: Definir el Formato de Pol√≠ticas de Taint (Sin Cambios).**
    
    **Como** Ingeniero de Seguridad, **quiero** un formato de fichero TOML intuitivo para definir qu√© son las `Sources` (fuentes), `Sinks` (sumideros) y `Sanitizers` (sanitizadores), y que me permita a√±adir **etiquetas de dominio de datos** (ej. `PII`, `Finance`, `Credentials`), **para que** el an√°lisis de flujo pueda rastrear no solo la contaminaci√≥n, sino tambi√©n el **tipo** de datos sensibles, y para que pueda a√±adir nuevas definiciones de vulnerabilidades sin recompilar el motor.

*   **Criterios de Aceptaci√≥n:**
    *   [ ] `structs` de Rust (`TaintPolicy`, `SourceDefinition`, etc.) que pueden ser deserializadas desde un fichero TOML.
    *   [ ] La `SourceDefinition` debe incluir un campo opcional `tags: Vec<String>`.
    *   [ ] El `TaintPropagator` (`HU-20.02`) debe ser modificado para propagar estas etiquetas junto con el estado de "taint".
    *   [ ] La estructura de resultado `TaintFlow` debe incluir las etiquetas que llegaron desde la fuente hasta el sumidero.


### **HU-20.04: Implementar el Motor de An√°lisis de Connascence.** üÜï **NUEVO**

**Como** desarrollador del motor, **quiero** crear un m√≥dulo `ConnascenceAnalyzer` que opere sobre el `SemanticModel` y pueda identificar y clasificar diferentes tipos de acoplamiento (Connascence), **para que** los extractores puedan detectar autom√°ticamente "malos olores" arquitect√≥nicos y de dise√±o.

**Estado Real:** ‚ùå NO IMPLEMENTADO - Requiere implementaci√≥n completa desde cero

*   **Criterios de Aceptaci√≥n:**
    #### **Connascence Est√°tica (Acoplamiento de C√≥digo Fuente)**

    Estos tipos son visibles analizando el c√≥digo sin ejecutarlo. Nuestro extractor de Nivel 3 est√° **perfectamente posicionado** para detectarlos.
    
    1.  **Connascence de Nombre (CoN):**
        *   **¬øQu√© es?:** Un componente se refiere a otro por su nombre. `moduloA.funcionX()`.
        *   **Viabilidad de Detecci√≥n:** **Trivial.** Es la forma m√°s b√°sica de dependencia. Nuestra Tabla de S√≠mbolos y Grafo de Llamadas ya modelan esto.
        *   **Veredicto:** ‚úÖ **Implementado por defecto.**
    
    2.  **Connascence de Tipo (CoT):**
        *   **¬øQu√© es?:** Dos componentes deben estar de acuerdo en un tipo de dato. `function procesarUsuario(usuario: User)`.
        *   **Viabilidad de Detecci√≥n:** **Trivial** para lenguajes de tipado est√°tico (Java, Rust). M√°s complejo pero **viable** para lenguajes din√°micos (Python, JS) usando an√°lisis de inferencia de tipos.
        *   **Veredicto:** ‚úÖ **Viable y Muy Valioso.**
    
    3.  **Connascence de Significado (CoM):**
        *   **¬øQu√© es?:** Dos componentes deben estar de acuerdo en el significado de un valor. `if (estado == 2) // 2 significa 'Completado'`.
        *   **Viabilidad de Detecci√≥n:** **Viable con heur√≠sticas.** Podemos detectar "valores m√°gicos" (literales hardcodeados) que se repiten en diferentes partes del sistema. Es una se√±al fuerte de CoM.
        *   **Veredicto:** ‚úÖ **Viable y Muy Valioso.** Es una de las detecciones m√°s importantes para la mantenibilidad.
    
    4.  **Connascence de Posici√≥n (CoP):**
        *   **¬øQu√© es?:** El orden de los argumentos importa. `crearUsuario("Juan", "P√©rez", 30)`.
        *   **Viabilidad de Detecci√≥n:** **Viable y Relativamente F√°cil.** Podemos detectar llamadas a funciones/constructores con m√∫ltiples par√°metros del mismo tipo primitivo.
        *   **Veredicto:** ‚úÖ **Viable y Muy Valioso.** Otro "quick win".
    
    5.  **Connascence de Algoritmo (CoA):**
        *   **¬øQu√© es?:** Dos componentes deben usar el mismo algoritmo para ser compatibles (ej. el cliente y el servidor deben usar el mismo algoritmo de compresi√≥n/encriptaci√≥n).
        *   **Viabilidad de Detecci√≥n:** **Dif√≠cil pero Parcialmente Viable.** No podemos "entender" un algoritmo complejo de forma abstracta. PERO, podemos detectar patrones como:
            *   Ambos lados llaman a la misma funci√≥n criptogr√°fica (`sha256(...)`).
            *   Ambos lados usan la misma librer√≠a de serializaci√≥n (ej. `JSON.stringify` en JS y `ObjectMapper` en Java).
            *   Detectar que dos implementaciones manuales del mismo algoritmo son compatibles es un problema a nivel de investigaci√≥n (casi imposible de forma gen√©rica).
        *   **Veredicto:** ‚ö†Ô∏è **Parcialmente Viable.** Podemos detectar el uso de algoritmos *conocidos*, pero no verificar la compatibilidad de algoritmos *implementados a mano*. Debemos enfocarnos en lo primero.


### **HU-20.05: Definir los Hechos At√≥micos Arquitect√≥nicos (`Coupling`, `ApiEndpoint`).**

**Como** arquitecto de la plataforma, **quiero** que el Esquema del IR (`.capnp`) se extienda para incluir nuevos `FactTypes` como `Coupling` y `ApiEndpoint`, **para que** los resultados de los an√°lisis arquitect√≥nicos puedan ser reportados de forma est√°ndar y consumidos por el motor de pol√≠ticas DSL, permitiendo la creaci√≥n de reglas de gobernanza de dise√±o.

*   **Criterios de Aceptaci√≥n:**
    *   [ ] El fichero `schema.capnp` define la nueva estructura `Coupling` con campos como `entity_a`, `entity_b`, `connascence_type`, `strength`.
    *   [ ] El fichero `schema.capnp` define la nueva estructura `ApiEndpoint` con campos como `function_name`, `route`, `http_method`.
    *   [ ] Las estructuras de Rust correspondientes se generan y se integran en el `enum FactType`.

---

### **√âPICA-21 (v2.0): Extractor Profundo para JavaScript/TypeScript**

**Objetivo (Actualizado):** Implementar el primer "Agente de √âlite" que no solo encuentre vulnerabilidades, sino que tambi√©n eval√∫e la calidad del dise√±o en el ecosistema din√°mico de JavaScript.

*   **HU-21.01: Construir el Traductor a `SemanticModel` (Incluyendo Scopes).**
    > **Como** desarrollador del extractor de JS, **quiero** que el traductor de `tree-sitter` a `SemanticModel` modele correctamente los **√°mbitos l√©xicos (lexical scopes) y el `hoisting` de JavaScript**, **para que** el an√°lisis de flujo de datos y de Connascence sea preciso.
    *   *Tareas:* Implementar la l√≥gica para rastrear `var`, `let`, `const`, clausuras (closures) y el `this` contextual.

*   **HU-21.02: Implementar el An√°lisis de Taint (Sin Cambios).**
    > *Esta historia de usuario se mantiene igual.*

*   **HU-21.03 (NUEVA): Detectar y Reportar Connascence en JavaScript.**
    > **Como** desarrollador senior de JavaScript, **quiero** que el extractor detecte patrones de acoplamiento fuerte comunes en JS, como la dependencia de argumentos posicionales en funciones (`CoP`) o el uso compartido de objetos globales (`CoI`), **para que** podamos promover un c√≥digo m√°s modular y mantenible.
    *   *Tareas:*
        *   Orquestar la ejecuci√≥n del `ConnascenceAnalyzer` de la librer√≠a central sobre el `SemanticModel` de JS.
        *   Generar Hechos `FactType::Coupling` para los problemas detectados.
        *   Crear una pol√≠tica YAML de Nivel 2 para detectar el uso de "strings m√°gicos" en `switch` o `if/else if` (`CoM`).

---

### **√âPICA-22 (v2.0): Extractor Profundo para Java**

**Objetivo (Actualizado):** Proveer an√°lisis de seguridad y arquitect√≥nico de primer nivel para el ecosistema empresarial de Java, entendiendo su sistema de tipos y patrones de dise√±o.

*   **HU-22.01: Construir el Traductor a `SemanticModel` (Incluyendo Jerarqu√≠a de Tipos).**
    > **Como** desarrollador del extractor de Java, **quiero** que el `SemanticModel` para Java represente con precisi√≥n la **jerarqu√≠a de herencia de clases y la implementaci√≥n de interfaces**, **para que** el an√°lisis pueda entender el polimorfismo y las dependencias de tipo.
    *   *Tareas:* El traductor debe ser capaz de resolver la herencia (`extends`), las interfaces (`implements`) y las anotaciones.

*   **HU-22.02: Implementar el An√°lisis de Taint (Sin Cambios).**
    > *Esta historia de usuario se mantiene igual.*

*   **HU-22.03 (NUEVA): Analizar Patrones de Dise√±o y Connascence en Java.**
    > **Como** arquitecto de Java, **quiero** que el extractor detecte "anti-patrones" que generan acoplamiento fuerte, como la **Connascence de Posici√≥n** en constructores con muchos par√°metros, o la **Connascence de Algoritmo** donde dos clases dependen de una implementaci√≥n de `hashCode()` compatible, **para que** podamos guiar a los equipos hacia un dise√±o m√°s limpio.
    *   *Tareas:*
        *   Ejecutar el `ConnascenceAnalyzer`.
        *   Crear una pol√≠tica TOML para el an√°lisis de Taint que modele la serializaci√≥n de Java como un `Sink` peligroso (un ejemplo de `CoA`).

---

### **√âpicas 23 (Python) y 24 (Rust) - Actualizaci√≥n similar**

Las √âpicas para Python y Rust seguir√≠an el mismo patr√≥n de actualizaci√≥n:

1.  **La Historia de Usuario del `SemanticModel` se enriquece** para incluir las caracter√≠sticas espec√≠ficas del lenguaje (ej. √°mbitos din√°micos para Python, lifetimes y traits para Rust).
2.  **Se a√±ade una nueva Historia de Usuario** para ejecutar el `ConnascenceAnalyzer` y detectar patrones de acoplamiento espec√≠ficos de ese ecosistema, generando Hechos `FactType::Coupling`.

### El Resultado Final: Pol√≠ticas Arquitect√≥nicas en Acci√≥n

Esta actualizaci√≥n de las √âpicas asegura que, al final de la implementaci√≥n, no solo podremos escribir pol√≠ticas de seguridad como esta:
```cedar
// Pol√≠tica de Seguridad (ya posible antes)
forbid(...) on { exists(TaintSink { category: "SqlQuery" }) }
```
Sino que tambi√©n podremos escribir **pol√≠ticas de dise√±o arquitect√≥nico** como esta:
```cedar
// Pol√≠tica Arquitect√≥nica (posible gracias a la actualizaci√≥n)
forbid(
  rule: "DESIGN-001-AVOID-POSITIONAL-COUPLING",
  severity: "Major",
  description: "Se detect√≥ Connascence de Posici√≥n. Refactoriza usando un objeto de par√°metros (Builder Pattern o un DTO) para mejorar la legibilidad y reducir errores."
) on {
  exists(Fact { type: "Coupling", connascence_type: "Position" })
}
```

Al integrar la Connascence y el an√°lisis de √°mbitos en el n√∫cleo de nuestros extractores m√°s potentes, `hodei-scan` cumple su promesa de ser una verdadera plataforma de **inteligencia de ingenier√≠a.**


