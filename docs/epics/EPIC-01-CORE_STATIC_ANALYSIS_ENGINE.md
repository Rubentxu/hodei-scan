# √âPICA-01: CORE STATIC ANALYSIS ENGINE

**Versi√≥n:** 2.0
**Fecha:** 10 de noviembre de 2025
**Story Points:** 89 SP
**Sprint Estimado:** 6 sprints
**Dependencias:** Ninguna (√âPICA BASE)
**Estado:** üöÄ Ready for Implementation

---

## üìã Descripci√≥n de la √âpica

Esta √©pica implementa el **core del motor de an√°lisis est√°tico basado en Arquitectura IR (Intermediate Representation)** que separa la extracci√≥n de datos de la evaluaci√≥n de reglas. Es la foundation sobre la cual se construyen todas las dem√°s funcionalidades de hodei-scan v2.0.

**Cambio de Paradigma:**
```
v1.0 (Obsoleto):  Parsing ‚Üí Rules ‚Üí Findings (Acoplado a lenguajes)
v2.0 (IR):        Parsers ‚Üí IR ‚Üí DSL ‚Üí Findings (Universal y escalable)
```

**Objetivo Principal:** Establecer una arquitectura IR que resuelva los problemas de escalabilidad y permita an√°lisis universales cross-language con correlaci√≥n multi-dominio.

---

## üéØ Objetivos y Alcance

### Objetivos Estrat√©gicos
1. **Implementar IR Schema v2.0** - Facts universales + correlaciones cross-domain
2. **Desarrollar Rule Engine DSL** - Motor que consulta IR (no ASTs)
3. **Crear extractores multi-lenguaje** - JS/Python/Go ‚Üí IR
4. **Establecer caching layer** - IR storage y retrieval optimizado
5. **Implementar WASM runtime** - Sandbox para reglas custom

### Alcance Funcional
- ‚úÖ **IR Core Engine**: Schema, facts, correlaciones
- ‚úÖ **Rule Engine DSL**: Parser + evaluator
- ‚úÖ **JavaScript Extractor**: Oxc ‚Üí IR
- ‚úÖ **Python Extractor**: tree-sitter + ruff ‚Üí IR
- ‚úÖ **Go Extractor**: tree-sitter ‚Üí IR
- ‚úÖ **TypeScript Extractor**: Oxc ‚Üí IR
- ‚úÖ **Caching System**: Redis + PostgreSQL
- ‚úÖ **WASM Sandbox**: Runtime para reglas custom
- ‚úÖ **Performance Benchmarks**: vs SonarQube/CodeQL

### Fuera de Alcance
- ‚ùå Frontend UI (√âPICA-WEB-01+)
- ‚ùå Security rules espec√≠ficas (√âPICA-02)
- ‚ùå SCA analysis (√âPICA-03)
- ‚ùå Code coverage (√âPICA-04)

---

## üë• Historias de Usuario

### US-01: IR Schema Definition
**Como** arquitecto de software
**Quiero** definir un IR Schema v2.0 que represente facts universales
**Para** desacoplar la extracci√≥n de la evaluaci√≥n de reglas

**Criterios de Aceptaci√≥n:**
```
GIVEN un c√≥digo fuente en cualquier lenguaje
WHEN el sistema analiza el c√≥digo
THEN se genera un IR con facts universales independientes del lenguaje

GIVEN facts de seguridad, calidad, coverage y dependencias
WHEN se almacenan en IR
THEN se pueden correlacionar cross-domain

GIVEN un IR schema v2.0
WHEN se serializa con Cap'n Proto
THEN el tama√±o es 10x menor que JSON

GIVEN un analysis_id √∫nico
WHEN se genera IR
THEN incluye timestamp, metadata, facts, dependencies y correlations
```

**Tareas T√©cnicas:**
- [ ] Dise√±ar IR Schema v2.0 con Fact, FactType, CodeLocation
- [ ] Implementar FactType enum con Security, Quality, Coverage, SCA
- [ ] Crear FactProvenance para tracking de source
- [ ] Implementar IR serialization con Cap'n Proto
- [ ] Crear IR deserialization
- [ ] Implementar Fact correlation engine
- [ ] Escribir tests unitarios para IR Schema

**TDD Tests:**
```rust
#[cfg(test)]
mod tests {
    #[test]
    fn should_create_ir_with_facts() {
        // Given: C√≥digo fuente
        // When: Se genera IR
        // Then: Contiene facts universales
    }

    #[test]
    fn should_serialize_ir_with_capnp() {
        // Given: IR con facts
        // When: Se serializa
        // Then: Tama√±o es 10x menor que JSON
    }

    #[test]
    fn should_correlate_facts_cross_domain() {
        // Given: Facts de security + coverage
        // When: Se correlacionan
        // Then: Se genera correlated fact
    }

    #[test]
    fn should_handle_multiple_fact_types() {
        // Given: Facts de security, quality, coverage
        // When: Se procesan
        // Then: Todos se almacenan correctamente
    }
}
```

---

### US-02: Cedar-Inspired DSL Rule Engine
**Como** security engineer
**Quiero** definir reglas usando una DSL Cedar-inspired
**Para** escribir reglas universales que funcionen en todos los lenguajes

**Criterios de Aceptaci√≥n:**
```
GIVEN una regla en DSL: permit(rule: "SEC-001", severity: "critical") on { unsafe_call + sql_sink }
WHEN se eval√∫a contra IR facts
THEN se genera un finding con severidad critical si la condici√≥n se cumple

GIVEN una regla DSL con correlaciones
WHEN se eval√∫a
THEN funciona igual en JS, Python, Go

GIVEN un parser de DSL
WHEN recibe una regla malformada
THEN retorna error detallado con l√≠nea y columna

GIVEN m√∫ltiples reglas
WHEN se eval√∫an en paralelo
THEN el tiempo de evaluaci√≥n es <100ms para 1000 facts
```

**Tareas T√©cnicas:**
- [ ] Dise√±ar DSL grammar basada en Cedar
- [ ] Implementar parser combinator con Nom
- [ ] Crear rule evaluator engine
- [ ] Implementar parallel evaluation con Rayon
- [ ] Crear error handling con context
- [ ] Implementar rule caching
- [ ] Escribir tests de parser y evaluator

**TDD Tests:**
```rust
#[cfg(test)]
mod dsl_tests {
    #[test]
    fn should_parse_simple_rule() {
        // Given: DSL string
        // When: Se parsea
        // Then: Se genera AST correcto
    }

    #[test]
    fn should_evaluate_rule_against_ir() {
        // Given: Regla DSL + IR facts
        // When: Se eval√∫a
        // Then: Se generan findings correctos
    }

    #[test]
    fn should_handle_rule_syntax_error() {
        // Given: DSL malformado
        // When: Se parsea
        // Then: Error con l√≠nea y columna
    }

    #[test]
    fn should_evaluate_rules_in_parallel() {
        // Given: 1000 reglas + facts
        // When: Se eval√∫an en paralelo
        // Then: Tiempo <100ms
    }

    #[test]
    fn should_cache_evaluated_rules() {
        // Given: Regla evaluada
        // When: Se vuelve a evaluar con mismos facts
        // Then: Se usa cache (10x m√°s r√°pido)
    }
}
```

---

### US-03: JavaScript Extractor (Oxc)
**Como** developer
**Quiero** que el sistema extraiga facts de JavaScript usando Oxc
**Para** tener an√°lisis universal de c√≥digo JS

**Criterios de Aceptaci√≥n:**
```
GIVEN un archivo JavaScript (.js, .mjs, .cjs)
WHEN se analiza con Oxc
THEN se extraen facts: functions, variables, unsafe_calls, dependencies

GIVEN c√≥digo TypeScript
WHEN se analiza
THEN se extraen facts de tipos y sem√°ntica

GIVEN un proyecto de 100K LOC JS
WHEN se extrae IR
THEN toma <5 segundos

GIVEN Oxc semantic model
WHEN se extraen facts
THEN se convierten a IR facts universales
```

**Tareas T√©cnicas:**
- [ ] Integrar Oxc parser library
- [ ] Implementar semantic analyzer adapter
- [ ] Crear mapper Oxc ‚Üí IR facts
- [ ] Implementar AST traversal
- [ ] Crear error handling para parsing errors
- [ ] Optimizar performance para 100K LOC
- [ ] Escribir tests con c√≥digo JS real

**TDD Tests:**
```rust
#[cfg(test)]
mod js_extractor_tests {
    #[test]
    fn should_extract_facts_from_js_file() {
        // Given: Archivo JS con function y variable
        // When: Se extrae IR
        // Then: Contiene Function y Variable facts
    }

    #[test]
    fn should_extract_unsafe_calls() {
        // Given: C√≥digo con eval(), innerHTML
        // When: Se analiza
        // Then: Se extraen UnsafeCall facts
    }

    #[test]
    fn should_handle_typescript() {
        // Given: Archivo TS con tipos
        // When: Se analiza
        // Then: Se extraen facts de tipos
    }

    #[test]
    fn should_process_100k_loc_in_5s() {
        // Given: Proyecto JS 100K LOC
        // When: Se extrae IR
        // Then: Tiempo <5s
    }

    #[test]
    fn should_handle_parse_errors_gracefully() {
        // Given: JS con syntax error
        // When: Se parsea
        // Then: Error con location y contexto
    }
}
```

---

### US-04: Python Extractor (tree-sitter + ruff)
**Como** developer
**Quiero** que el sistema extraiga facts de Python usando tree-sitter y ruff
**Para** tener an√°lisis universal de c√≥digo Python

**Criterios de Aceptaci√≥n:**
```
GIVEN un archivo Python (.py)
WHEN se analiza con tree-sitter + ruff
THEN se extraen facts: functions, classes, variables, imports, unsafe_calls

GIVEN c√≥digo Python con type hints
WHEN se analiza
THEN se extraen facts de tipos

GIVEN un proyecto Python con 50K LOC
WHEN se extrae IR
THEN toma <3 segundos

GIVEN tree-sitter AST + ruff diagnostics
WHEN se combinan
THEN se generan IR facts completos
```

**Tareas T√©cnicas:**
- [ ] Integrar tree-sitter-python
- [ ] Integrar ruff library
- [ ] Crear mapper AST + diagnostics ‚Üí IR facts
- [ ] Implementar symbol table extraction
- [ ] Crear import resolution
- [ ] Optimizar para 50K LOC
- [ ] Escribir tests con c√≥digo Python real

**TDD Tests:**
```rust
#[cfg(test)]
mod python_extractor_tests {
    #[test]
    fn should_extract_facts_from_py_file() {
        // Given: Archivo Python con class y function
        // When: Se extrae IR
        // Then: Contiene Class y Function facts
    }

    #[test]
    fn should_extract_ruff_diagnostics() {
        // Given: C√≥digo con ruff violations
        // When: Se analiza
        // Then: Se extraen facts de calidad
    }

    #[test]
    fn should_extract_imports() {
        // Given: C√≥digo con imports
        // When: Se extrae IR
        // Then: Contiene Dependency facts
    }

    #[test]
    fn should_handle_type_hints() {
        // Given: C√≥digo con type hints
        // When: Se analiza
        // Then: Se extraen Type facts
    }
}
```

---

### US-05: Go Extractor (tree-sitter)
**Como** developer
**Quiero** que el sistema extraiga facts de Go usando tree-sitter
**Para** tener an√°lisis universal de c√≥digo Go

**Criterios de Aceptaci√≥n:**
```
GIVEN un archivo Go (.go)
WHEN se analiza con tree-sitter-go
THEN se extraen facts: functions, structs, variables, imports, interfaces

GIVEN c√≥digo Go con generics
WHEN se analiza
THEN se extraen facts de tipos

GIVEN un proyecto Go con 100K LOC
WHEN se extrae IR
THEN toma <4 segundos

GIVEN Go modules
WHEN se analizan
THEN se extraen dependency facts
```

**Tareas T√©cnicas:**
- [ ] Integrar tree-sitter-go
- [ ] Implementar Go semantic analyzer
- [ ] Crear mapper Go AST ‚Üí IR facts
- [ ] Implementar Go modules resolution
- [ ] Crear interface extraction
- [ ] Optimizar para 100K LOC
- [ ] Escribir tests con c√≥digo Go real

**TDD Tests:**
```rust
#[cfg(test)]
mod go_extractor_tests {
    #[test]
    fn should_extract_facts_from_go_file() {
        // Given: Archivo Go con struct y function
        // When: Se extrae IR
        // Then: Contiene Struct y Function facts
    }

    #[test]
    fn should_extract_interfaces() {
        // Given: C√≥digo con interfaces
        // When: Se extrae IR
        // Then: Contiene Interface facts
    }

    #[test]
    fn should_handle_generics() {
        // Given: C√≥digo con generics
        // When: Se analiza
        // Then: Se extraen Type facts
    }

    #[test]
    fn should_extract_go_modules() {
        // Given: go.mod file
        // When: Se analiza
        // Then: Se extraen Dependency facts
    }
}
```

---

### US-06: TypeScript Extractor
**Como** developer
**Quiero** que el sistema extraiga facts de TypeScript usando Oxc
**Para** tener an√°lisis universal de c√≥digo TypeScript

**Criterios de Aceptaci√≥n:**
```
GIVEN un archivo TypeScript (.ts, .tsx)
WHEN se analiza con Oxc
THEN se extraen facts: functions, interfaces, types, unsafe_calls

GIVEN c√≥digo TypeScript con generics y conditional types
WHEN se analiza
THEN se extraen facts de tipos complejos

GIVEN un proyecto TS de 150K LOC
WHEN se extrae IR
THEN toma <6 segundos

GIVEN Oxc semantic model
WHEN se extraen types
THEN se preserva informaci√≥n sem√°ntica
```

**Tareas T√©cnicas:**
- [ ] Integrar Oxc para TypeScript
- [ ] Implementar type resolver
- [ ] Crear mapper TS ‚Üí IR facts
- [ ] Implementar generics handling
- [ ] Crear interface merging
- [ ] Optimizar para 150K LOC
- [ ] Escribir tests con c√≥digo TS real

**TDD Tests:**
```rust
#[cfg(test)]
mod ts_extractor_tests {
    #[test]
    fn should_extract_facts_from_ts_file() {
        // Given: Archivo TypeScript con interface
        // When: Se extrae IR
        // Then: Contiene Interface y Type facts
    }

    #[test]
    fn should_extract_generics() {
        // Given: C√≥digo con generics
        // When: Se analiza
        // Then: Se extraen GenericType facts
    }

    #[test]
    fn should_handle_jsx() {
        // Given: Archivo TSX
        // When: Se extrae IR
        // Then: Contiene JSXElement facts
    }

    #[test]
    fn should_extract_conditional_types() {
        // Given: C√≥digo con conditional types
        // When: Se analiza
        // Then: Se extraen Type facts
    }
}
```

---

### US-07: Caching System (Redis + PostgreSQL)
**Como** developer
**Quiero** un sistema de caching inteligente para IR
**Para** acelerar an√°lisis incrementales 30-120x

**Criterios de Aceptaci√≥n:**
```
GIVEN un archivo modificado
WHEN se re-analiza
THEN se usa IR cache y toma <1s (vs 30-120s sin cache)

GIVEN un analysis_id
WHEN se guarda IR en cache
THEN se almacena en Redis para acceso r√°pido

GIVEN datos hist√≥ricos
WHEN se necesitan persistencia
THEN se almacenan en PostgreSQL

GIVEN cache miss
WHEN se necesita IR
THEN se recalcula y se cachea autom√°ticamente
```

**Tareas T√©cnicas:**
- [ ] Dise√±ar cache key strategy
- [ ] Implementar Redis cache layer
- [ ] Implementar PostgreSQL persistence
- [ ] Crear cache invalidation strategy
- [ ] Implementar cache warming
- [ ] Crear cache hit/miss metrics
- [ ] Escribir tests de cache

**TDD Tests:**
```rust
#[cfg(test)]
mod cache_tests {
    #[test]
    fn should_cache_ir_with_key() {
        // Given: IR y analysis_id
        // When: Se cachea
        // Then: Se puede recuperar con key
    }

    #[test]
    fn should_retrieve_cached_ir() {
        // Given: IR cacheado
        // When: Se recupera
        // Then: Datos id√©nticos al original
    }

    #[test]
    fn should_invalidate_cache_on_change() {
        // Given: IR cacheado
        // When: Archivo cambia
        // Then: Cache se invalida
    }

    #[test]
    fn should_warm_cache_preemptively() {
        // Given: Archivos frecuentemente accedidos
        // When: Sistema idle
        // Then: Se pre-cargan en cache
    }

    #[test]
    fn should_persist_to_postgresql() {
        // Given: Datos hist√≥ricos
        // When: Se persisten
        // Then: Disponibles despu√©s de restart
    }
}
```

---

### US-08: WASM Runtime for Custom Rules
**Como** security engineer
**Quiero** ejecutar reglas custom en sandbox WASM
**Para** tener reglas enterprise seguras sin comprometer el core

**Criterios de Aceptaci√≥n:**
```
GIVEN una regla custom en WASM
WHEN se ejecuta en sandbox
THEN no puede acceder al filesystem ni red

GIVEN m√∫ltiples reglas WASM
WHEN se ejecutan
THEN est√°n aisladas entre s√≠

GIVEN una regla con infinite loop
WHEN se ejecuta
THEN se termina despu√©s de timeout configurable

GIVEN reglas WASM compiled
WHEN se cargan
THEN tiempo de carga <100ms
```

**Tareas T√©cnicas:**
- [ ] Integrar WASM runtime (Wasmtime)
- [ ] Implementar sandbox isolation
- [ ] Crear rule loader
- [ ] Implementar timeout mechanism
- [ ] Crear memory limits
- [ ] Implementar error handling
- [ ] Escribir tests de sandbox

**TDD Tests:**
```rust
#[cfg(test)]
mod wasm_tests {
    #[test]
    fn should_load_wasm_rule() {
        // Given: WASM rule binary
        // When: Se carga
        // Then: Se puede ejecutar
    }

    #[test]
    fn should_isolate_wasm_execution() {
        // Given: WASM rule ejecut√°ndose
        // When: Intenta acceso a filesystem
        // Then: Error de sandbox violation
    }

    #[test]
    fn should_timeout_infinite_loop() {
        // Given: WASM rule con infinite loop
        // When: Se ejecuta
        // Then: Termina por timeout
    }

    #[test]
    fn should_enforce_memory_limit() {
        // Given: WASM rule que usa mucha memoria
        // When: Se ejecuta
        // Then: Termina por memory limit
    }
}
```

---

### US-09: Performance Benchmarking
**Como** technical lead
**Quiero** comparar performance vs SonarQube y CodeQL
**Para** validar ventajas del paradigma IR

**Criterios de Aceptaci√≥n:**
```
GIVEN proyecto 100K LOC
WHEN se analiza con hodei-scan
THEN toma <5s (vs 5min SonarQube = 60x m√°s r√°pido)

GIVEN an√°lisis incremental
WHEN se re-analiza archivo modificado
THEN toma <1s (vs 30-120s SonarQube = 30-120x m√°s r√°pido)

GIVEN rule evaluation
WHEN se eval√∫an 1000 reglas sobre IR cacheado
THEN toma <100ms (vs 10-20ms SonarQube)

GIVEN 6 lenguajes soportados
WHEN se a√±ade lenguaje 7
THEN toma 2-3 semanas (vs 3-6 meses SonarQube)
```

**Tareas T√©cnicas:**
- [ ] Crear benchmarking suite
- [ ] Implementar comparison metrics
- [ ] Crear test projects (JS, Python, Go, TS)
- [ ] Implementar performance profiling
- [ ] Crear automated reports
- [ ] Integrar CI benchmarking
- [ ] Escribir benchmarks tests

**TDD Tests:**
```rust
#[cfg(test)]
mod benchmark_tests {
    #[test]
    fn should_analyze_100k_loc_in_5s() {
        // Given: Proyecto 100K LOC
        // When: Se analiza
        // Then: Tiempo <5s
    }

    #[test]
    fn should_do_incremental_in_1s() {
        // Given: IR cacheado
        // When: Se re-analiza archivo modificado
        // Then: Tiempo <1s
    }

    #[test]
    fn should_evaluate_1000_rules_in_100ms() {
        // Given: 1000 reglas + IR
        // When: Se eval√∫an
        // Then: Tiempo <100ms
    }

    #[test]
    fn should_measure_cache_hit_ratio() {
        // Given: Sistema con cache
        // When: Se hacen m√∫ltiples an√°lisis
        // Then: Cache hit ratio >90%
    }
}
```

---

## ‚úÖ Criterios de Validaci√≥n

### Funcionales
- [ ] IR Schema v2.0 implementado y documentado
- [ ] DSL Parser/Evaluator funcional para reglas universales
- [ ] Extractores para JS, Python, Go, TypeScript operativos
- [ ] Caching layer con >90% hit ratio
- [ ] WASM sandbox seguro y funcional
- [ ] Benchmarks superan targets establecidos

### No Funcionales
- [ ] **Performance**: <5s para 100K LOC
- [ ] **Escalabilidad**: O(N+M) vs O(N√óM) tradicional
- [ ] **Accuracy**: >95% consistency cross-language
- [ ] **False Positives**: <10%
- [ ] **Cache Hit Ratio**: >90%
- [ ] **Memory Usage**: <800MB pico
- [ ] **Startup Time**: <2s cold start

### Calidad de C√≥digo
- [ ] Cobertura de tests: >90%
- [ ] Linting: 100% pass
- [ ] Documentaci√≥n KDoc: 100% p√∫blicas
- [ ] Review de c√≥digo: 2 approvals
- [ ] CI pipeline: 100% green

---

## üìä M√©tricas de √âxito

| M√©trica | Target | Actual | Status |
|---------|--------|--------|--------|
| **IR Generation Speed** | <5s / 100K LOC | - | ‚è≥ |
| **Rule Evaluation** | <100ms cached | - | ‚è≥ |
| **Incremental Analysis** | <1s changes | - | ‚è≥ |
| **Cache Hit Ratio** | >90% | - | ‚è≥ |
| **Multi-language Accuracy** | >95% consistency | - | ‚è≥ |
| **False Positive Rate** | <10% | - | ‚è≥ |
| **System Uptime** | 99.9% | - | ‚è≥ |
| **Add New Language** | 2-3 semanas | - | ‚è≥ |

---

## üîó Dependencias

### Internas
- Ninguna (√âPICA BASE)

### Externas
- **Oxc Parser** (JavaScript/TypeScript)
- **tree-sitter** (Python, Go)
- **ruff** (Python linting)
- **Redis** (caching)
- **PostgreSQL** (persistence)
- **Wasmtime** (WASM runtime)
- **Cap'n Proto** (serialization)
- **Tokio** (async runtime)
- **Axum** (HTTP framework)
- **Rayon** (parallelism)

---

## ‚ö†Ô∏è Riesgos y Mitigaci√≥n

| Riesgo | Probabilidad | Impacto | Mitigaci√≥n |
|--------|-------------|---------|------------|
| **Oxc API instability** | Media | Alto | Usar version pinning + wrapper |
| **Performance targets no alcanzados** | Media | Alto | Early benchmarking + optimization |
| **IR Schema changes** | Alta | Medio | Versioning strategy + migration |
| **WASM complexity** | Media | Medio | Start simple + iterate |
| **Cross-language consistency** | Alta | Alto | Comprehensive test suite |

---

## üöÄ Plan de Implementaci√≥n

### Sprint 1 (2 semanas): IR Foundation
- Implementar IR Schema v2.0
- Crear Cap'n Proto serialization
- Implementar base Fact structures

### Sprint 2 (2 semanas): DSL Engine
- Implementar DSL parser
- Crear rule evaluator
- Implementar parallel evaluation

### Sprint 3 (2 semanas): JavaScript Extractor
- Integrar Oxc
- Implementar mapper JS ‚Üí IR
- Optimizar performance

### Sprint 4 (2 semanas): Python + Go Extractors
- Implementar Python extractor (tree-sitter + ruff)
- Implementar Go extractor (tree-sitter)
- Cross-language validation

### Sprint 5 (2 semanas): TypeScript Extractor
- Implementar TypeScript extractor
- Generics + conditional types support
- Integration testing

### Sprint 6 (2 semanas): Caching + WASM + Benchmarks
- Implementar caching system
- Implementar WASM sandbox
- Create benchmarking suite
- Performance validation

---

## üìö Referencias T√©cnicas

- [IR Architecture Specification](./ARCHITECTURE.md#ir-architecture)
- [TDD Methodology](../TDD_METHODOLOGY.md)
- [Oxc Documentation](https://oxc-project.github.io/)
- [tree-sitter](https://tree-sitter.github.io/)
- [Cedar Policy Language](https://cedarpolicy.github.io/)
- [Cap'n Proto](https://capnproto.org/)
- [Wasmtime](https://wasmtime.dev/)

---

**Estado:** ‚úÖ Documentaci√≥n Completa - Ready for Development
**Pr√≥ximos Pasos:** Crear EPIC-02-SECURITY_ANALYSIS_SAST.md
