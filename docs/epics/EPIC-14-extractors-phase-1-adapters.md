# EPIC-14: Ecosistema de Extractores - Fase 1 (Adaptadores)
## Cosecha RÃ¡pida: IntegraciÃ³n de Herramientas Existentes

**VersiÃ³n:** 1.0.0  
**Fecha CreaciÃ³n:** 2025-11-12  
**Estado:** Propuesta  
**Prioridad:** CrÃ­tica  
**Fase:** v3.3 - Q1 2025

---

## ğŸ“‹ Resumen Ejecutivo

### Objetivo EstratÃ©gico

Conseguir una cobertura de anÃ¡lisis masiva (cientos de reglas) en mÃºltiples lenguajes durante el primer mes de desarrollo, integrando herramientas lÃ­deres del mercado mediante un sistema de adaptadores estandarizado basado en SARIF.

### Propuesta de Valor

**Para usuarios**: Acceso inmediato a anÃ¡lisis de calidad y seguridad de cÃ³digo mediante herramientas probadas en la industria (Ruff, ESLint, Clippy, etc.) bajo una interfaz unificada de `hodei-scan`.

**Para el proyecto**: Establecer rÃ¡pidamente presencia en el mercado con cobertura comparable a soluciones enterprise (SonarQube, Snyk) sin escribir lÃ³gica de anÃ¡lisis desde cero.

### MÃ©tricas de Ã‰xito

- âœ… **Cobertura**: >500 reglas activas en 4+ lenguajes principales
- âœ… **Velocidad**: AnÃ¡lisis completo de proyecto medio (100K LOC) en <30 segundos
- âœ… **Calidad**: <5% tasa de falsos positivos en benchmarks de seguridad
- âœ… **AdopciÃ³n**: Compatibilidad con 100% de herramientas que exportan SARIF

---

## ğŸ¯ Contexto y MotivaciÃ³n

### AnÃ¡lisis del Problema

El desarrollo de extractores nativos es costoso en tiempo:
- Implementar parser para cada lenguaje: 4-8 semanas por lenguaje
- Definir y probar reglas: 2-3 dÃ­as por regla de calidad
- Mantener actualizaciones con estÃ¡ndares del lenguaje: esfuerzo continuo

**Alternativa estratÃ©gica**: Integrar herramientas existentes que ya resuelven estos problemas.

### Benchmarking de Competidores

| Herramienta | Estrategia | Cobertura | Tiempo al Mercado |
|-------------|-----------|-----------|-------------------|
| **SonarQube** | Motores nativos + integraciones | 25+ lenguajes, 5000+ reglas | 10+ aÃ±os desarrollo |
| **Semgrep** | Motor propio + reglas community | 30+ lenguajes, 2000+ reglas | 3+ aÃ±os desarrollo |
| **CodeQL** | Motor propietario GitHub | 12 lenguajes, 1000+ queries | 5+ aÃ±os (adquirido) |
| **hodei-scan v3.3** | **Adaptadores + AgregaciÃ³n** | **4-6 lenguajes, 500+ reglas** | **4-6 semanas** |

### Estrategia de Tres Niveles

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ESTRATEGIA DE EXTRACTORES                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  NIVEL 1: ADAPTADORES (Esta Ã‰pica)                      â”‚
â”‚  â”œâ”€ Objetivo: Cobertura masiva rÃ¡pida                   â”‚
â”‚  â”œâ”€ Esfuerzo: 4-6 semanas                               â”‚
â”‚  â”œâ”€ Resultado: 500+ reglas, 4+ lenguajes                â”‚
â”‚  â””â”€ Valor: "Fast follower" del mercado                  â”‚
â”‚                                                          â”‚
â”‚  NIVEL 2: EXTRACTORES DECLARATIVOS                      â”‚
â”‚  â”œâ”€ Objetivo: Democratizar creaciÃ³n de reglas           â”‚
â”‚  â”œâ”€ Esfuerzo: 6-10 semanas                              â”‚
â”‚  â”œâ”€ Resultado: DSL YAML + motor tree-sitter             â”‚
â”‚  â””â”€ Valor: Reglas custom en <5 minutos                  â”‚
â”‚                                                          â”‚
â”‚  NIVEL 3: EXTRACTORES PROFUNDOS                         â”‚
â”‚  â”œâ”€ Objetivo: AnÃ¡lisis de vanguardia (taint analysis)   â”‚
â”‚  â”œâ”€ Esfuerzo: 12-16 semanas por lenguaje                â”‚
â”‚  â”œâ”€ Resultado: DetecciÃ³n de vulnerabilidades complejas  â”‚
â”‚  â””â”€ Valor: Diferenciador competitivo                    â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ Arquitectura del Sistema de Adaptadores

### Contrato del Extractor

Todo extractor debe implementar este contrato:

```rust
/// Contrato estÃ¡ndar para extractores de hodei-scan
pub trait Extractor {
    /// Ejecuta el anÃ¡lisis y retorna IR en formato Cap'n Proto
    fn extract(&self, config: ExtractorConfig) -> Result<IntermediateRepresentation>;
    
    /// Metadatos del extractor
    fn metadata(&self) -> ExtractorMetadata;
}

/// ConfiguraciÃ³n de entrada para extractores
pub struct ExtractorConfig {
    /// Ruta al proyecto a analizar
    pub project_path: PathBuf,
    /// ConfiguraciÃ³n especÃ­fica del extractor en JSON
    pub extractor_settings: serde_json::Value,
    /// Paths de archivos a incluir/excluir
    pub file_filters: FileFilters,
}

/// Metadatos del extractor
pub struct ExtractorMetadata {
    pub id: String,
    pub name: String,
    pub version: semver::Version,
    pub supported_languages: Vec<String>,
    pub capabilities: ExtractorCapabilities,
}
```

### Flujo de EjecuciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. hodei-scan CLI lee hodei.toml                           â”‚
â”‚     extractors:                                             â”‚
â”‚       - id: sarif-universal                                 â”‚
â”‚         command: hodei-extract-sarif                        â”‚
â”‚       - id: ruff-python                                     â”‚
â”‚         command: hodei-extract-ruff                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Orquestador ejecuta extractores en paralelo             â”‚
â”‚     â€¢ Cada extractor recibe config via stdin (JSON)         â”‚
â”‚     â€¢ Cada extractor escribe IR a stdout (Cap'n Proto)      â”‚
â”‚     â€¢ Logs van a stderr                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Agregador valida y fusiona IRs                          â”‚
â”‚     â€¢ Valida cada IR contra esquema                         â”‚
â”‚     â€¢ Elimina duplicados por fingerprint                    â”‚
â”‚     â€¢ Enriquece con metadatos de correlaciÃ³n                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Motor de EvaluaciÃ³n procesa IR unificado                â”‚
â”‚     â€¢ Carga en Ã­ndices espaciales                           â”‚
â”‚     â€¢ Ejecuta reglas de correlaciÃ³n                         â”‚
â”‚     â€¢ Genera hallazgos agregados                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Formato SARIF - El Rosetta Stone

SARIF (Static Analysis Results Interchange Format) es el estÃ¡ndar OASIS 2.1.0 adoptado por:
- GitHub Advanced Security
- Microsoft Security Code Analysis
- Checkmarx
- Veracode
- Fortify
- 50+ herramientas mÃ¡s

**Estructura bÃ¡sica**:

```json
{
  "$schema": "https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json",
  "version": "2.1.0",
  "runs": [
    {
      "tool": {
        "driver": {
          "name": "ESLint",
          "version": "8.50.0",
          "rules": [
            {
              "id": "no-eval",
              "shortDescription": {"text": "Disallow eval()"},
              "properties": {
                "security-severity": "9.0"
              }
            }
          ]
        }
      },
      "results": [
        {
          "ruleId": "no-eval",
          "level": "error",
          "message": {"text": "eval() can execute arbitrary code"},
          "locations": [{
            "physicalLocation": {
              "artifactLocation": {"uri": "src/unsafe.js"},
              "region": {"startLine": 42, "startColumn": 5}
            }
          }],
          "properties": {
            "security-severity": "9.0"
          }
        }
      ]
    }
  ]
}
```

**Mapeo SARIF â†’ hodei-scan IR**:

| Campo SARIF | Campo IR | TransformaciÃ³n |
|-------------|----------|----------------|
| `ruleId` | `Fact::rule_id` | Directo |
| `level` (error/warning) | `Fact::severity` | Mapeo: error=HIGH, warning=MEDIUM, note=LOW |
| `message.text` | `Fact::message` | Directo |
| `physicalLocation` | `Fact::location` | ConversiÃ³n a ProjectPath + Span |
| `properties.security-severity` | `Fact::confidence_score` | NormalizaciÃ³n a 0.0-1.0 |
| `properties.tags` | `Fact::categories` | ExtracciÃ³n de categorÃ­as (security, quality, etc.) |

---

## ğŸ“Š Historias de Usuario

### US-14.1: Infraestructura Core de OrquestaciÃ³n

**Como** desarrollador del core  
**Quiero** un orquestador que ejecute extractores en paralelo y agregue sus IRs  
**Para** poder integrar mÃºltiples herramientas sin acoplamiento

**Criterios de AceptaciÃ³n**:
- âœ… Lee configuraciÃ³n de extractores desde `hodei.toml`
- âœ… Ejecuta extractores como procesos hijos
- âœ… Captura stdout (IR) y stderr (logs) independientemente
- âœ… Implementa timeout configurable por extractor (default: 5 min)
- âœ… Maneja fallos gracefully (continÃºa con otros extractores)
- âœ… Valida cada IR contra esquema Cap'n Proto
- âœ… Fusiona IRs eliminando duplicados por fingerprint
- âœ… Genera mÃ©tricas de ejecuciÃ³n (timing, hechos por extractor)

**EstimaciÃ³n**: 5 Story Points (1 semana)

**Tareas TÃ©cnicas**:
1. DiseÃ±ar esquema de configuraciÃ³n en `hodei.toml`
2. Implementar `ExtractorOrchestrator` con proceso pool
3. Crear sistema de fingerprinting para deduplicaciÃ³n
4. Implementar validaciÃ³n de esquema Cap'n Proto
5. Escribir tests de integraciÃ³n con extractores mock

**Pruebas**:
```rust
#[test]
fn test_orchestrator_parallel_execution() {
    let config = ExtractorConfig::from_toml("fixtures/hodei.toml");
    let orchestrator = ExtractorOrchestrator::new(config);
    
    let ir = orchestrator.run_all_extractors().unwrap();
    
    // Verifica que todos los extractores ejecutaron
    assert_eq!(ir.metadata.extractor_runs.len(), 3);
    
    // Verifica deduplicaciÃ³n
    let unique_facts: HashSet<_> = ir.facts.iter()
        .map(|f| f.fingerprint())
        .collect();
    assert_eq!(unique_facts.len(), ir.facts.len());
}
```

---

### US-14.2: Extractor Universal SARIF

**Como** usuario de GitHub Advanced Security  
**Quiero** importar mis reportes SARIF directamente a hodei-scan  
**Para** unificar mi anÃ¡lisis de seguridad

**Criterios de AceptaciÃ³n**:
- âœ… Parsea ficheros SARIF 2.1.0 vÃ¡lidos
- âœ… Mapea correctamente todos los campos clave a IR
- âœ… Soporta mÃºltiples runs en un fichero SARIF
- âœ… Extrae security-severity cuando estÃ¡ presente
- âœ… Maneja gracefully campos opcionales ausentes
- âœ… Genera warnings para reglas sin metadata completa
- âœ… Throughput >10K resultados/segundo

**EstimaciÃ³n**: 3 Story Points (3-4 dÃ­as)

**Esquema de ConfiguraciÃ³n**:
```toml
[[extractors]]
id = "sarif-universal"
command = "hodei-extract-sarif"
enabled = true

[extractors.config]
# Ruta a fichero SARIF o glob pattern
sarif_files = ["results/**/*.sarif"]
# Filtros opcionales
exclude_rules = ["style/*", "deprecated/*"]
min_severity = "warning"
```

**ImplementaciÃ³n**:
```rust
pub struct SarifExtractor {
    config: SarifConfig,
}

impl Extractor for SarifExtractor {
    fn extract(&self, input: ExtractorConfig) -> Result<IntermediateRepresentation> {
        let mut ir_builder = IRBuilder::new();
        
        for sarif_path in self.discover_sarif_files(&input.project_path)? {
            let sarif: SarifReport = serde_json::from_reader(
                BufReader::new(File::open(&sarif_path)?)
            )?;
            
            for run in sarif.runs {
                self.process_run(&run, &mut ir_builder)?;
            }
        }
        
        Ok(ir_builder.build())
    }
    
    fn metadata(&self) -> ExtractorMetadata {
        ExtractorMetadata {
            id: "sarif-universal".into(),
            name: "SARIF Universal Importer".into(),
            version: semver::Version::new(1, 0, 0),
            supported_languages: vec!["*".into()],
            capabilities: ExtractorCapabilities {
                provides_facts: vec![
                    FactType::Vulnerability,
                    FactType::CodeSmell,
                    FactType::Bug,
                ],
                requires_source_code: false,
            },
        }
    }
}

impl SarifExtractor {
    fn process_run(&self, run: &SarifRun, ir: &mut IRBuilder) -> Result<()> {
        let tool_name = &run.tool.driver.name;
        let tool_version = &run.tool.driver.version;
        
        for result in &run.results {
            let fact = self.sarif_result_to_fact(result, tool_name, tool_version)?;
            ir.add_fact(fact);
        }
        
        Ok(())
    }
    
    fn sarif_result_to_fact(
        &self,
        result: &SarifResult,
        tool: &str,
        version: &str,
    ) -> Result<Fact> {
        let location = self.extract_location(&result.locations[0])?;
        let severity = self.map_severity(&result.level);
        
        let fact_type = if result.properties.get("security-severity").is_some() {
            FactType::Vulnerability(VulnerabilityFact {
                cwe_ids: self.extract_cwe_ids(result),
                security_severity: result.properties["security-severity"]
                    .as_f64()
                    .unwrap_or(5.0) / 10.0, // Normaliza a 0.0-1.0
            })
        } else {
            FactType::CodeSmell(CodeSmellFact {
                smell_type: result.rule_id.clone(),
            })
        };
        
        Ok(Fact {
            id: FactId::generate(),
            fact_type,
            location,
            message: result.message.text.clone(),
            severity,
            provenance: Provenance {
                extractor_id: format!("sarif-{}", tool),
                extractor_version: version.into(),
                extracted_at: SystemTime::now(),
                source_file: Some(result.rule_id.clone()),
            },
            metadata: HashMap::new(),
        })
    }
    
    fn map_severity(&self, level: &str) -> Severity {
        match level {
            "error" => Severity::High,
            "warning" => Severity::Medium,
            "note" | "none" => Severity::Low,
            _ => Severity::Medium,
        }
    }
}
```

**Pruebas**:
```rust
#[test]
fn test_sarif_github_security() {
    let extractor = SarifExtractor::default();
    let config = ExtractorConfig {
        project_path: "fixtures/github-security".into(),
        extractor_settings: json!({
            "sarif_files": ["security-results.sarif"]
        }),
        file_filters: FileFilters::default(),
    };
    
    let ir = extractor.extract(config).unwrap();
    
    // Verifica que se importaron vulnerabilidades
    let vulns: Vec<_> = ir.facts.iter()
        .filter(|f| matches!(f.fact_type, FactType::Vulnerability(_)))
        .collect();
    
    assert!(vulns.len() > 0);
    
    // Verifica mapeo de security-severity
    let high_severity = vulns.iter()
        .filter(|f| f.severity == Severity::High)
        .count();
    assert!(high_severity > 0);
}
```

---

### US-14.3: Adaptador Ruff (Python)

**Como** desarrollador de Python  
**Quiero** que hodei-scan ejecute Ruff automÃ¡ticamente  
**Para** aprovechar sus 700+ reglas sin instalar herramientas adicionales

**Criterios de AceptaciÃ³n**:
- âœ… Ejecuta `ruff check` con configuraciÃ³n personalizable
- âœ… Parsea salida JSON de Ruff
- âœ… Mapea cÃ³digos de error de Ruff a categorÃ­as de hodei-scan
- âœ… Respeta configuraciÃ³n `.ruff.toml` del proyecto si existe
- âœ… Soporta fixing automÃ¡tico opcional
- âœ… Rendimiento: >100K LOC/segundo

**EstimaciÃ³n**: 2 Story Points (2-3 dÃ­as)

**ConfiguraciÃ³n**:
```toml
[[extractors]]
id = "ruff-python"
command = "hodei-extract-ruff"
enabled = true

[extractors.config]
# Selectores de reglas (ver https://docs.astral.sh/ruff/rules/)
select = ["E", "F", "B", "S", "I"]  # Errors, pyflakes, bugbear, security, imports
ignore = ["E501"]  # Line too long

# Opciones de fixing
fix = false
fix_only = false

# Paths a incluir
include = ["*.py"]
exclude = ["tests/fixtures/**"]
```

**ImplementaciÃ³n**:
```rust
pub struct RuffExtractor {
    config: RuffConfig,
}

impl Extractor for RuffExtractor {
    fn extract(&self, input: ExtractorConfig) -> Result<IntermediateRepresentation> {
        // Ejecuta Ruff como subprocess
        let output = Command::new("ruff")
            .arg("check")
            .arg(&input.project_path)
            .arg("--format")
            .arg("json")
            .args(self.build_ruff_args())
            .output()?;
        
        if !output.status.success() && output.stdout.is_empty() {
            return Err(ExtractorError::ToolFailed {
                tool: "ruff",
                stderr: String::from_utf8_lossy(&output.stderr).into(),
            });
        }
        
        let ruff_results: Vec<RuffViolation> = serde_json::from_slice(&output.stdout)?;
        
        let mut ir_builder = IRBuilder::new();
        for violation in ruff_results {
            let fact = self.ruff_violation_to_fact(violation)?;
            ir_builder.add_fact(fact);
        }
        
        Ok(ir_builder.build())
    }
    
    fn metadata(&self) -> ExtractorMetadata {
        ExtractorMetadata {
            id: "ruff-python".into(),
            name: "Ruff Python Linter".into(),
            version: self.get_ruff_version().unwrap_or_default(),
            supported_languages: vec!["python".into()],
            capabilities: ExtractorCapabilities {
                provides_facts: vec![
                    FactType::CodeSmell,
                    FactType::Bug,
                    FactType::Vulnerability,
                ],
                requires_source_code: true,
            },
        }
    }
}

#[derive(Debug, Deserialize)]
struct RuffViolation {
    code: String,
    message: String,
    location: RuffLocation,
    end_location: RuffLocation,
    filename: PathBuf,
    noqa_row: Option<usize>,
}

#[derive(Debug, Deserialize)]
struct RuffLocation {
    row: usize,
    column: usize,
}

impl RuffExtractor {
    fn ruff_violation_to_fact(&self, violation: RuffViolation) -> Result<Fact> {
        let location = Location {
            file: ProjectPath::new(&violation.filename)?,
            span: Span {
                start: Position {
                    line: violation.location.row as u32,
                    column: violation.location.column as u32,
                },
                end: Position {
                    line: violation.end_location.row as u32,
                    column: violation.end_location.column as u32,
                },
            },
        };
        
        let (fact_type, severity) = self.categorize_ruff_code(&violation.code);
        
        Ok(Fact {
            id: FactId::generate(),
            fact_type,
            location,
            message: violation.message,
            severity,
            provenance: Provenance {
                extractor_id: "ruff-python".into(),
                extractor_version: self.get_ruff_version().unwrap_or_default(),
                extracted_at: SystemTime::now(),
                source_file: Some(violation.code.clone()),
            },
            metadata: HashMap::from([
                ("ruff_code".into(), violation.code.into()),
            ]),
        })
    }
    
    fn categorize_ruff_code(&self, code: &str) -> (FactType, Severity) {
        // Mapeo de prefijos de cÃ³digo Ruff a categorÃ­as
        match code.chars().next() {
            Some('E') | Some('W') => {
                // Errores de estilo/sintaxis
                (FactType::CodeSmell(CodeSmellFact {
                    smell_type: "style".into(),
                }), Severity::Low)
            }
            Some('F') => {
                // Pyflakes (bugs lÃ³gicos)
                (FactType::Bug(BugFact {
                    bug_category: "logic_error".into(),
                }), Severity::Medium)
            }
            Some('B') => {
                // Bugbear (anti-patterns)
                (FactType::CodeSmell(CodeSmellFact {
                    smell_type: "anti_pattern".into(),
                }), Severity::Medium)
            }
            Some('S') => {
                // Bandit (seguridad)
                (FactType::Vulnerability(VulnerabilityFact {
                    cwe_ids: vec![],
                    security_severity: 0.6,
                }), Severity::High)
            }
            _ => {
                (FactType::CodeSmell(CodeSmellFact {
                    smell_type: "other".into(),
                }), Severity::Low)
            }
        }
    }
    
    fn get_ruff_version(&self) -> Result<semver::Version> {
        let output = Command::new("ruff")
            .arg("--version")
            .output()?;
        
        let version_str = String::from_utf8_lossy(&output.stdout);
        let version = version_str
            .split_whitespace()
            .nth(1)
            .ok_or(ExtractorError::VersionParsing)?;
        
        Ok(semver::Version::parse(version)?)
    }
}
```

**Pruebas**:
```rust
#[test]
fn test_ruff_security_detection() {
    let extractor = RuffExtractor::default();
    let config = ExtractorConfig {
        project_path: "fixtures/python-insecure".into(),
        extractor_settings: json!({
            "select": ["S"]  // Solo reglas de seguridad
        }),
        file_filters: FileFilters::default(),
    };
    
    let ir = extractor.extract(config).unwrap();
    
    // Fixture tiene 'eval(user_input)' que Ruff detecta como S307
    let eval_vuln = ir.facts.iter()
        .find(|f| matches!(f.fact_type, FactType::Vulnerability(_)))
        .expect("Should detect eval vulnerability");
    
    assert_eq!(eval_vuln.severity, Severity::High);
    assert!(eval_vuln.message.contains("eval"));
}

#[test]
fn test_ruff_performance() {
    // Proyecto con ~50K LOC Python
    let start = Instant::now();
    
    let extractor = RuffExtractor::default();
    let ir = extractor.extract(ExtractorConfig {
        project_path: "fixtures/large-python-project".into(),
        extractor_settings: json!({}),
        file_filters: FileFilters::default(),
    }).unwrap();
    
    let duration = start.elapsed();
    
    // Ruff debe analizar 50K LOC en <5 segundos
    assert!(duration < Duration::from_secs(5));
    assert!(ir.facts.len() > 100);
}
```

---

### US-14.4: Adaptador ESLint (JavaScript/TypeScript)

**Como** desarrollador de JavaScript/TypeScript  
**Quiero** que hodei-scan ejecute ESLint automÃ¡ticamente  
**Para** detectar bugs y vulnerabilidades en mi cÃ³digo frontend/backend

**Criterios de AceptaciÃ³n**:
- âœ… Ejecuta ESLint con configuraciÃ³n del proyecto (.eslintrc)
- âœ… Soporta TypeScript mediante plugin
- âœ… Parsea salida JSON de ESLint
- âœ… Mapea niveles de severidad correctamente
- âœ… Detecta vulnerabilidades de seguridad (ej: no-eval, no-innerHTML)
- âœ… Rendimiento: >50K LOC/segundo

**EstimaciÃ³n**: 2 Story Points (2-3 dÃ­as)

**ConfiguraciÃ³n**:
```toml
[[extractors]]
id = "eslint-javascript"
command = "hodei-extract-eslint"
enabled = true

[extractors.config]
# Config override (opcional, respeta .eslintrc por defecto)
extends = ["eslint:recommended", "plugin:security/recommended"]
rules = { "no-eval" = "error", "no-console" = "warn" }

# Paths
include = ["**/*.js", "**/*.jsx", "**/*.ts", "**/*.tsx"]
exclude = ["node_modules/**", "dist/**"]

# Plugins
plugins = ["security", "@typescript-eslint"]
```

**ImplementaciÃ³n destacada**:
```rust
impl ESLintExtractor {
    fn eslint_message_to_fact(&self, msg: ESLintMessage, file: &Path) -> Result<Fact> {
        let location = Location {
            file: ProjectPath::new(file)?,
            span: Span {
                start: Position {
                    line: msg.line as u32,
                    column: msg.column as u32,
                },
                end: Position {
                    line: msg.end_line.unwrap_or(msg.line) as u32,
                    column: msg.end_column.unwrap_or(msg.column + 1) as u32,
                },
            },
        };
        
        let severity = match msg.severity {
            2 => Severity::High,  // ESLint "error"
            1 => Severity::Medium, // ESLint "warning"
            _ => Severity::Low,
        };
        
        // Detecta si es vulnerabilidad de seguridad
        let is_security = msg.rule_id.as_ref()
            .map(|id| id.starts_with("security/") || 
                      SECURITY_RULES.contains(id.as_str()))
            .unwrap_or(false);
        
        let fact_type = if is_security {
            FactType::Vulnerability(VulnerabilityFact {
                cwe_ids: self.map_eslint_rule_to_cwe(msg.rule_id.as_ref()),
                security_severity: 0.7,
            })
        } else {
            FactType::CodeSmell(CodeSmellFact {
                smell_type: msg.rule_id.clone().unwrap_or_default(),
            })
        };
        
        Ok(Fact {
            id: FactId::generate(),
            fact_type,
            location,
            message: msg.message,
            severity,
            provenance: Provenance {
                extractor_id: "eslint-javascript".into(),
                extractor_version: self.get_eslint_version()?,
                extracted_at: SystemTime::now(),
                source_file: msg.rule_id,
            },
            metadata: HashMap::new(),
        })
    }
    
    fn map_eslint_rule_to_cwe(&self, rule_id: Option<&String>) -> Vec<u32> {
        // Mapeo manual de reglas ESLint a CWEs
        match rule_id.map(|s| s.as_str()) {
            Some("no-eval") => vec![95, 94], // CWE-95: Eval Injection
            Some("security/detect-non-literal-regexp") => vec![625], // CWE-625: RegEx DoS
            Some("security/detect-sql-injection") => vec![89], // CWE-89: SQL Injection
            _ => vec![],
        }
    }
}

const SECURITY_RULES: &[&str] = &[
    "no-eval",
    "no-implied-eval",
    "no-new-func",
    "no-script-url",
];
```

---

### US-14.5: Adaptador Clippy (Rust)

**Como** desarrollador de Rust  
**Quiero** que hodei-scan ejecute Clippy automÃ¡ticamente  
**Para** mantener cÃ³digo idiomÃ¡tico y detectar errores sutiles

**Criterios de AceptaciÃ³n**:
- âœ… Ejecuta `cargo clippy` con lints configurables
- âœ… Parsea salida JSON de Clippy
- âœ… Distingue entre correctness, performance, style
- âœ… Soporta lints pedantic y nursery opcionales
- âœ… Integra con `Cargo.toml` del proyecto

**EstimaciÃ³n**: 2 Story Points (2-3 dÃ­as)

---

### US-14.6: Adaptador staticcheck (Go)

**Como** desarrollador de Go  
**Quiero** que hodei-scan ejecute staticcheck automÃ¡ticamente  
**Para** detectar bugs comunes y anti-patterns

**Criterios de AceptaciÃ³n**:
- âœ… Ejecuta `staticcheck` sobre mÃ³dulos Go
- âœ… Parsea salida JSON
- âœ… Mapea categorÃ­as de checks (SA, ST, QF, etc.)
- âœ… Soporta configuraciÃ³n via `staticcheck.conf`

**EstimaciÃ³n**: 2 Story Points (2-3 dÃ­as)

---

### US-14.7: Sistema de DeduplicaciÃ³n Inteligente

**Como** usuario que ejecuta mÃºltiples extractores  
**Quiero** que hodei-scan elimine hallazgos duplicados automÃ¡ticamente  
**Para** ver un reporte limpio sin ruido

**Criterios de AceptaciÃ³n**:
- âœ… Calcula fingerprint estable por hallazgo
- âœ… Agrupa hallazgos por fingerprint
- âœ… Selecciona "mejor" hallazgo del grupo (criterios: severidad, confianza)
- âœ… Preserva metadatos de origen de todos los extractores
- âœ… <1ms por 1000 hechos procesados

**EstimaciÃ³n**: 3 Story Points (3-4 dÃ­as)

**Algoritmo de Fingerprinting**:
```rust
impl Fact {
    /// Calcula fingerprint estable para deduplicaciÃ³n
    pub fn fingerprint(&self) -> FactFingerprint {
        let mut hasher = blake3::Hasher::new();
        
        // Componentes del fingerprint
        hasher.update(self.location.file.as_str().as_bytes());
        hasher.update(&self.location.span.start.line.to_le_bytes());
        hasher.update(&self.location.span.start.column.to_le_bytes());
        
        // Tipo de hecho (sin metadatos especÃ­ficos)
        let type_discriminant = std::mem::discriminant(&self.fact_type);
        hasher.update(&format!("{:?}", type_discriminant).as_bytes());
        
        // Primeras 50 chars del mensaje (normalizado)
        let normalized_msg = self.message
            .chars()
            .filter(|c| c.is_alphanumeric())
            .take(50)
            .collect::<String>()
            .to_lowercase();
        hasher.update(normalized_msg.as_bytes());
        
        FactFingerprint(hasher.finalize().as_bytes()[..16].try_into().unwrap())
    }
}

pub struct FactDeduplicator {
    fingerprints: HashMap<FactFingerprint, Vec<Fact>>,
}

impl FactDeduplicator {
    pub fn deduplicate(&mut self, facts: Vec<Fact>) -> Vec<Fact> {
        // Agrupa por fingerprint
        for fact in facts {
            let fp = fact.fingerprint();
            self.fingerprints.entry(fp)
                .or_insert_with(Vec::new)
                .push(fact);
        }
        
        // Selecciona el "mejor" de cada grupo
        self.fingerprints
            .values()
            .map(|group| self.select_best_fact(group))
            .collect()
    }
    
    fn select_best_fact(&self, group: &[Fact]) -> Fact {
        // Criterios de selecciÃ³n (en orden):
        // 1. Mayor severidad
        // 2. Mayor confianza (si es vulnerabilidad)
        // 3. Extractor mÃ¡s reciente
        
        let mut best = &group[0];
        
        for fact in &group[1..] {
            if fact.severity > best.severity {
                best = fact;
            } else if fact.severity == best.severity {
                // Desempate por confianza
                if let (
                    FactType::Vulnerability(v1),
                    FactType::Vulnerability(v2),
                ) = (&fact.fact_type, &best.fact_type) {
                    if v1.security_severity > v2.security_severity {
                        best = fact;
                    }
                }
            }
        }
        
        // Enriquece con metadatos de todos los extractores
        let mut result = best.clone();
        result.metadata.insert(
            "also_found_by".into(),
            group.iter()
                .map(|f| &f.provenance.extractor_id)
                .collect::<Vec<_>>()
                .join(", ")
                .into(),
        );
        
        result
    }
}
```

---

## ğŸ“ˆ Plan de ImplementaciÃ³n

### Timeline Semanal

**Semana 1: Fundamentos**
- DÃ­a 1-2: US-14.1 (Orquestador) - DiseÃ±o + ImplementaciÃ³n inicial
- DÃ­a 3-4: US-14.1 (Orquestador) - Tests + ValidaciÃ³n
- DÃ­a 5: US-14.2 (SARIF) - Inicio

**Semana 2: Adaptador Universal + Python**
- DÃ­a 1-2: US-14.2 (SARIF) - Completar + Tests
- DÃ­a 3-4: US-14.3 (Ruff) - ImplementaciÃ³n
- DÃ­a 5: US-14.3 (Ruff) - Tests + Benchmarks

**Semana 3: JavaScript + DeduplicaciÃ³n**
- DÃ­a 1-2: US-14.4 (ESLint) - ImplementaciÃ³n
- DÃ­a 3: US-14.4 (ESLint) - Tests
- DÃ­a 4-5: US-14.7 (DeduplicaciÃ³n) - ImplementaciÃ³n

**Semana 4: Rust + Go + IntegraciÃ³n**
- DÃ­a 1-2: US-14.5 (Clippy) + US-14.6 (staticcheck)
- DÃ­a 3: US-14.7 (DeduplicaciÃ³n) - Completar tests
- DÃ­a 4-5: Tests de integraciÃ³n end-to-end

**Semana 5: Pulido + DocumentaciÃ³n**
- OptimizaciÃ³n de rendimiento
- DocumentaciÃ³n de usuario
- GuÃ­as de configuraciÃ³n

### Dependencias

```
US-14.1 (Orquestador)
    â”œâ”€> US-14.2 (SARIF)
    â”œâ”€> US-14.3 (Ruff)
    â”œâ”€> US-14.4 (ESLint)
    â”œâ”€> US-14.5 (Clippy)
    â””â”€> US-14.6 (staticcheck)

US-14.2..14.6 (Todos los extractores)
    â””â”€> US-14.7 (DeduplicaciÃ³n)
```

### Riesgos y Mitigaciones

| Riesgo | Probabilidad | Impacto | MitigaciÃ³n |
|--------|--------------|---------|------------|
| Herramientas externas no instaladas | Alta | Medio | Detectar ausencia + mensaje claro de instalaciÃ³n |
| Formatos de salida cambian entre versiones | Media | Alto | Versionar parsers + tests con mÃºltiples versiones |
| Rendimiento de subprocess overhead | Baja | Medio | Cachear resultados + ejecutar en paralelo |
| Conflictos en configuraciÃ³n de herramientas | Media | Bajo | Priorizar config de hodei.toml > config de proyecto |

---

## ğŸ¯ Criterios de FinalizaciÃ³n de Ã‰pica

### Funcionales
- âœ… Orquestador ejecuta 4+ extractores en paralelo
- âœ… Extractores para Python, JavaScript/TypeScript, Rust, Go funcionando
- âœ… Adaptador SARIF importa reportes de >=3 herramientas distintas
- âœ… DeduplicaciÃ³n reduce hallazgos en 20-40% en proyectos con mÃºltiples extractores
- âœ… ConfiguraciÃ³n en `hodei.toml` documentada y validada

### No Funcionales
- âœ… Benchmarks: AnÃ¡lisis de proyecto medio (100K LOC, 4 lenguajes) en <30s
- âœ… Tests: Cobertura >=80% en todo el cÃ³digo de extractores
- âœ… DocumentaciÃ³n: README por extractor + ejemplos de configuraciÃ³n
- âœ… CI/CD: Pipeline verde con tests de integraciÃ³n

### MÃ©tricas de Ã‰xito
- **Cobertura de reglas**: >=500 reglas activas
- **Rendimiento**: <=30s para proyecto medio
- **Calidad**: <5% tasa de falsos positivos en benchmark OWASP
- **Usabilidad**: Usuario puede configurar extractor en <5 minutos

---

## ğŸ“š Recursos y Referencias

### Especificaciones
- [SARIF 2.1.0 Specification](https://docs.oasis-open.org/sarif/sarif/v2.1.0/sarif-v2.1.0.html)
- [Ruff Rules Documentation](https://docs.astral.sh/ruff/rules/)
- [ESLint Rules Reference](https://eslint.org/docs/rules/)
- [Clippy Lints List](https://rust-lang.github.io/rust-clippy/master/)

### Implementaciones de Referencia
- [GitHub CodeQL Action](https://github.com/github/codeql-action) - Pipeline SARIF
- [Microsoft SARIF SDK](https://github.com/microsoft/sarif-sdk) - ValidaciÃ³n y utilidades

### Herramientas
- [sarif-tools](https://github.com/microsoft/sarif-tools) - CLI para manipular SARIF
- [ruff](https://github.com/astral-sh/ruff) - Linter Python ultra-rÃ¡pido
- [eslint](https://github.com/eslint/eslint) - Linter JavaScript estÃ¡ndar
- [clippy](https://github.com/rust-lang/rust-clippy) - Lints de Rust
- [staticcheck](https://staticcheck.io/) - AnÃ¡lisis estÃ¡tico para Go

---

**PrÃ³xima Ã‰pica**: EPIC-15 - Extractores Declarativos (Fase 2)
